{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8F28mYbZJUo"
   },
   "source": [
    "*(to use GPU in colab go to Runtime -> Change Runtime Type and change the hardware accelerator)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_Dd0j4pcw9-"
   },
   "outputs": [],
   "source": [
    "# some prelimenaries\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "\n",
    "print('Using torch version {}'.format(torch.__version__))\n",
    "print('Using {} device'.format(device))\n",
    "  \n",
    "# Training dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    MNIST(root='.', train=True, download=True,\n",
    "          transform=transforms.ToTensor()),\n",
    "    batch_size=100, shuffle=True, pin_memory=True)\n",
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    MNIST(root='.', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=100, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_c1mRNbLct6G"
   },
   "source": [
    "# Practical Session. Variational Autoencoders\n",
    "\n",
    "During this practical session, you will implement a vanilla VAE on MNIST and then a VAE extension with multiple latent variables. Both implementations will be based on classes for parametric probabilistic distributions from the torch [*torch.distributions*](https://pytorch.org/docs/stable/distributions.html) module to emphasize the probabilistic nature of the models.\n",
    "\n",
    "To complete the task, you will have read the notebook and construct two loss functions using the classes and then train the models.\n",
    "\n",
    "# AEs  vs. VAEs\n",
    "\n",
    "As illustrated below, autoencoders can provide good reconstruction quality. \n",
    "\n",
    "![Autoencoder reconstructions](https://github.com/bayesgroup/deepbayes-2018/blob/master/day2_vae/ae_reconstructions.png?raw=true)\n",
    "\n",
    "Still, the model has no control over the learned latent representations. For example, an interpolation of latent representations of two digits is typically not a latent representation for a digit:\n",
    "\n",
    "![Autoencoder interpolations](https://github.com/bayesgroup/deepbayes-2018/blob/master/day2_vae/ae_interpolations.png?raw=true)\n",
    "\n",
    "On the other hand, a standard VAE model forces latent representation to fit a multivariate Gaussian distribution. As a result, an interpolation of two latent representations is likely to be a latent representation of a digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCGwVlZWdUA-"
   },
   "source": [
    "# Distributions for VAE\n",
    "\n",
    "For the assignment, we will need two types of distributions to define the probabilistic model. For the representation $z$ we need a multivariate [normal distribution](https://pytorch.org/docs/stable/distributions.html#normal) with diagonal covariance matrix (to put another way, a vector of independent normal random variables). For observations $x$, we will need a vector of independent [Bernoulli](https://pytorch.org/docs/stable/distributions.html#bernoulli) random variables. By default, both classes model a tensor of independent random **variables**. To represent a matrix of independent random variables as a batch of random **vectors** you may also use the [Independent](https://pytorch.org/docs/stable/distributions.html#independent) class.\n",
    "\n",
    "### Bernoulli random vector\n",
    "\n",
    "While the class can be initialized both with probabilities and logits, the best practice is to initialize the class with logits. Otherwise, computing logarithm of probability can be highly unstable. \n",
    "\n",
    "In the tasks, you will use this class to model $p(x | z)$ parametrized by the output of the decoder. To define the loss function you will need to compute $\\log p(x | z)$ for input images using *log_prob()* method.\n",
    "\n",
    "### Normal Distribution\n",
    "\n",
    "In this task, you will use the class to define the approximate posterior distribution $q(x | z)$ and the latent variable distribution $p(z)$.\n",
    "\n",
    "Again, you will use *log_prob()* method to compute the loss function. Besides that, you will need to generate a sample from $q(x | z)$ to pass it to the decoder. To implement the reparametrization trick the class defines a specific method *rsample()*, that computes $z = \\mu(x) + \\varepsilon \\odot \\sigma(x)$ for standard Gaussian noise $\\varepsilon$. Notice that the implementation of *rsample()* method differs from the implementation of *sample()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9r_hPaHx0Jz1"
   },
   "outputs": [],
   "source": [
    "from torch.distributions import Normal, Bernoulli, Independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5wtFSf25dXjx"
   },
   "source": [
    "# Vanilla VAE\n",
    "\n",
    "A variational autoencoder consists of two components. The first component is a probabilistic model for observations: \n",
    "\\begin{align}\n",
    "& p(x, z \\mid \\theta) =  p(z) p(x \\mid z, \\theta) \\\\\n",
    "& p(z) = \\mathcal N(z \\mid 0, I) \\\\\n",
    "& p(x \\mid z, \\theta) = \\prod_{i = 1}^D p_i(z, \\theta)^{x_i} (1 - p_i(z, \\theta))^{1 - x_i}.\n",
    "\\end{align}\n",
    "The second component is a variational approximation, used to compute the lower bound on marginal likelihood (VAE uses the negative lower bound as a loss function)\n",
    "\\begin{equation}\n",
    "q(z \\mid x, \\phi) = \\mathcal N(z \\mid \\mu(x, \\phi), \\operatorname{diag}(\\sigma^2(x, \\phi))).\n",
    "\\end{equation}\n",
    "The lower bound for probability of observing $x$ from a minibatch is\n",
    "$$ \\mathcal L(x, \\theta, \\phi) = \\mathbb E_{q(z \\mid x, \\phi)} \\left[ \\log p(x \\mid z, \\phi) + \\log p(z) - \\log q(z \\mid x, \\theta) \\right] $$\n",
    "However, it is impossible to compute the expectation. The standard practice is to approximate it with the following one-sample Monte-Carlo estimate:\n",
    "\\begin{align*}\n",
    "\\log p(x \\mid z_0, \\phi) + \\log p(z_0) - \\log q(z_0 \\mid x, \\theta) \\\\\n",
    "z_0 = \\mu(x, \\phi) + \\sigma^2(x, \\phi)^T \\varepsilon_0 \\\\\n",
    "\\varepsilon_0 \\sim \\mathcal N(0, I)\n",
    "\\end{align*}\n",
    "*Note that this choice of the Monte-Carlo estimate for expectation is crucial and is typically reffered to as* **reparametrization trick.** For more details see [Auto-encoding Variational Bayes](https://arxiv.org/abs/1312.6114) paper.\n",
    "\n",
    "Finally, to train the model we average the lower bound values over the minibatch and then maximize the average with gradient ascent:\n",
    "$$ \\frac{1}{N} \\sum_{n=1}^N \\log p(x_n \\mid z_n, \\phi) + \\log p(z_n) - \\log q(z_n \\mid x_n, \\theta) \\rightarrow \\max_{\\theta, \\phi} $$\n",
    "## Encoder and decoder\n",
    "\n",
    "$q(z\\mid x, \\theta)$ is usually called encoder and $p(x \\mid z, \\phi)$ is usually called decoder. To parametrize these distributions we introduce two neural networks:\n",
    "\n",
    "- *enc* takes $x$ as input and return $2 \\times d$-dimensional vector to parametrize mean and standard deviation of $q(z \\mid x, \\theta)$\n",
    "- *dec* takes a latent representation $z$ and returns the logits of distribution $p(x \\mid z, \\phi)$.\n",
    "\n",
    "The computational graph has a simple structure of autoencoder. The only difference is that now it uses a stochastic variable $\\varepsilon$:\n",
    "\n",
    "![vae](https://github.com/bayesgroup/deepbayes-2018/blob/master/day2_vae/vae.png?raw=true)\n",
    "\n",
    "Below we initialize a couple of simple fully-connected networks to model the two distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pakTj8-gc6SZ"
   },
   "outputs": [],
   "source": [
    "d, nh, D = 32, 100, 28 * 28\n",
    "\n",
    "enc = nn.Sequential(\n",
    "    nn.Linear(D, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, 2 * d)) # note that the final layer outputs real values\n",
    "\n",
    "dec = nn.Sequential(\n",
    "    nn.Linear(d, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, D)).to(device) # <-----------------------------------------------\n",
    "\n",
    "enc = enc.to(device)\n",
    "dec = dec.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xqmyAtbfmhG"
   },
   "source": [
    "## Task 1: VAE Loss function\n",
    "\n",
    "Implement the loss function for the variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymwPo9E3erVB"
   },
   "outputs": [],
   "source": [
    "def loss_vae(x, encoder, decoder):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    returns\n",
    "    1. the avergave value of negative ELBO across the minibatch x\n",
    "    2. and the output of the decoder\n",
    "    \"\"\"\n",
    "    pass\n",
    "    #return loss, decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIMpMloYfyJT"
   },
   "source": [
    "## Training\n",
    "The cell below implements a simple training function that can be used for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qLI_soZRfzBM"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def train_model(loss, model, batch_size=100, num_epochs=3, learning_rate=1e-3):\n",
    "    gd = torch.optim.Adam(\n",
    "        chain(*[x.parameters() for x in model\n",
    "                if (isinstance(x, nn.Module) or isinstance(x, nn.Parameter))]),\n",
    "        lr=learning_rate)\n",
    "    train_losses = []\n",
    "    test_results = []\n",
    "    for _ in range(num_epochs):\n",
    "        for i, (batch, _) in enumerate(train_loader):\n",
    "            total = len(train_loader)\n",
    "            gd.zero_grad()\n",
    "            batch = batch.view(-1, D).to(device)\n",
    "            loss_value, _ = loss(batch, *model)\n",
    "            loss_value.backward()\n",
    "            train_losses.append(loss_value.item())\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print('\\rTrain loss:', train_losses[-1],\n",
    "                      'Batch', i + 1, 'of', total, ' ' * 10, end='', flush=True)\n",
    "            gd.step()\n",
    "        test_loss = 0.\n",
    "        for i, (batch, _) in enumerate(test_loader):\n",
    "            batch = batch.view(-1, D).to(device)\n",
    "            batch_loss, _ = loss(batch, *model)\n",
    "            test_loss += (batch_loss - test_loss) / (i + 1)\n",
    "        print('\\nTest loss after an epoch: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPjL_TOpf17s"
   },
   "outputs": [],
   "source": [
    "# my implementation has test loss = -110.59\n",
    "train_model(loss_vae, model=[enc, dec], num_epochs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "McWlphgdf5ip"
   },
   "source": [
    "## Visualisations\n",
    "\n",
    "- How do reconstruction compare to reconstructions of autoencoder?\n",
    "- Interpolations?\n",
    "- Is the latent space regularly covered? \n",
    "- Is there any dependence between T-SNE encoding and the digit label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pgFFrXPxkNAh"
   },
   "outputs": [],
   "source": [
    "def sample_vae(dec, n_samples=50):\n",
    "    with torch.no_grad():\n",
    "        samples = torch.sigmoid(dec(torch.randn(n_samples, d).to(device)))\n",
    "        samples = samples.view(n_samples, 28, 28).cpu().numpy()\n",
    "    return samples\n",
    "    \n",
    "def plot_samples(samples, h=5, w=10):\n",
    "    fig, axes = plt.subplots(nrows=h,\n",
    "                             ncols=w,\n",
    "                             figsize=(int(1.4 * w), int(1.4 * h)),\n",
    "                             subplot_kw={'xticks': [], 'yticks': []})\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.imshow(samples[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jX7z79vpAUp1"
   },
   "outputs": [],
   "source": [
    "plot_samples(sample_vae(dec=dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVfp4hfbf66d"
   },
   "outputs": [],
   "source": [
    "def plot_reconstructions(loss, model):\n",
    "    with torch.no_grad():\n",
    "        batch = (test_loader.dataset.data[:25].float() / 255.)\n",
    "        batch = batch.view(-1, D).to(device)\n",
    "        _, rec = loss(batch, *model)\n",
    "        rec = torch.sigmoid(rec)\n",
    "        rec = rec.view(-1, 28, 28).cpu().numpy()\n",
    "        batch = batch.view(-1, 28, 28).cpu().numpy()\n",
    "    \n",
    "        fig, axes = plt.subplots(nrows=5, ncols=10, figsize=(14, 7),\n",
    "                                 subplot_kw={'xticks': [], 'yticks': []})\n",
    "        for i in range(25):\n",
    "            axes[i % 5, 2 * (i // 5)].imshow(batch[i], cmap='gray')\n",
    "            axes[i % 5, 2 * (i // 5) + 1].imshow(rec[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fn1cLF_BgAN2"
   },
   "outputs": [],
   "source": [
    "plot_reconstructions(loss_vae, [enc, dec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ye1dch0gCmp"
   },
   "outputs": [],
   "source": [
    "def plot_interpolations(encoder, decoder):\n",
    "    with torch.no_grad():\n",
    "        batch = (test_loader.dataset.data[:10].float() / 255.)\n",
    "        batch = batch.view(-1, D).to(device)\n",
    "        batch = encoder(batch)\n",
    "        z_0 = batch[:5, :d].view(5, 1, d)\n",
    "        z_1 = batch[5:, :d].view(5, 1, d)\n",
    "        \n",
    "        alpha = torch.linspace(0., 1., 10).to(device)\n",
    "        alpha = alpha.view(1, 10, 1)\n",
    "        \n",
    "        interpolations_z = (z_0 * alpha + z_1 * (1 - alpha))\n",
    "        interpolations_z = interpolations_z.view(50, d)\n",
    "        interpolations_x = torch.sigmoid(decoder(interpolations_z))\n",
    "        interpolations_x = interpolations_x.view(5, 10, 28, 28).cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=5, ncols=10, figsize=(14, 7),\n",
    "                             subplot_kw={'xticks': [], 'yticks': []})\n",
    "    for i in range(50):\n",
    "        axes[i // 10, i % 10].imshow(interpolations_x[i // 10, i % 10], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vi5Kw-KOgFky"
   },
   "outputs": [],
   "source": [
    "plot_interpolations(enc, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tR-VF5QdgHSP"
   },
   "outputs": [],
   "source": [
    "def plot_tsne(objects, labels):\n",
    "    from sklearn.manifold import TSNE\n",
    "    embeddings = TSNE(n_components=2).fit_transform(objects)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for k in range(10):\n",
    "        embeddings_for_k = embeddings[labels == k]\n",
    "        plt.scatter(embeddings_for_k[:, 0], embeddings_for_k[:, 1],\n",
    "                    label='{}'.format(k))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vFlGlKogJ4i"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  batch = (test_loader.dataset.data[:1000].float() / 255.)\n",
    "  batch = batch.view(-1, D).to(device)\n",
    "  \n",
    "  latent_variables = enc(batch)[:, :d]\n",
    "  latent_variables = latent_variables.cpu().numpy()\n",
    "  labels = test_loader.dataset.targets[:1000].numpy()\n",
    "  \n",
    "plot_tsne(latent_variables, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wI6yAPTrgMVw"
   },
   "source": [
    "# [DRAW](http://proceedings.mlr.press/v37/gregor15.pdf)\n",
    "\n",
    "To illustrate the flexibility of VAE framework, this section considers Deep Recurrent Attentive Writer Model. The goal of the model was to improve image generation by allowing the model to generate images step-by-step. Instead of encoding image into a fixed-size latent representation $z$, the model uses a recurrent neural network to generate a sequence of representations $z_1, \\dots, z_T$ that capture the generation steps.\n",
    "\n",
    "From the probabilistic viewpoint, the model puts standard Gaussian prior over $p(z_i) = \\mathcal N(0, I)$ and uses Bernoulli distribution to model $p(x | z, \\theta)$ just as in the standard VAE. But now the encoder uses a flexible autoregressive model\n",
    "\\begin{align}\n",
    "q(z_1, \\dots, z_T \\mid x, \\phi) = \\prod_{t=1}^T q(z_t \\mid z_1, \\dots, z_{t-1}, x, \\phi).\n",
    "\\end{align}\n",
    "Equations (3)-(8) from the [paper](http://proceedings.mlr.press/v37/gregor15.pdf) describe the details of the architecture. At each timestep $t$ the model stores \"canvas\" $c_t$, a D-dimensional vector that sequentially approximates the input sample $x$. \n",
    "\n",
    "**First**, the recurrent *encoder* computes the approximation error $$\\hat{x}_t = x - \\sigma(c_{t -1})$$ and computes next hidden state $h^{enc}_t$ based on the approximation error $\\hat{x}_t$, the input sample $x$ and the hiddent state of decoder network:\n",
    "\\begin{align}\n",
    "r_t &= \\textit{read}(x, \\hat{x}_t, h_{t - 1}^{dec}) \\\\\n",
    "h_t^{enc} & = RNN^{enc} (h^{enc}_{t - 1}, [r_t, h_{t - 1}^{dec}]).\n",
    "\\end{align}\n",
    "**Second**, similarly to VAE, the hidden state $h_t^{enc}$ defines mean and variance of a fully-factorised Gaussian distribution\n",
    "$$z_t \\sim q(z_t \\mid h_t^{enc}).$$\n",
    "**Third**, the *decoder* RNN updates the canvas:\n",
    "\\begin{align}\n",
    "h^{dec}_t &= RNN^{dec}(h_{t - 1}^{dec}, z_t) \\\\\n",
    "c_t &= c_{t - 1} + \\textit{write}(h_t^{dec}) \\\\.\n",
    "\\end{align}\n",
    "\n",
    "After making $T$ timesteps the model computes $p(x | z)$ (i.e. reconstruction error) using the canvas $c_T$ as logits to initialize Bernoulli distribution.\n",
    "\n",
    "The $\\textit{read}$ and $\\textit{write}$ modules in the simplest instantiation are a concatenation of two inputs and a linear layer\n",
    "\\begin{align}\n",
    "\\textit{read}(x, \\hat{x}_t, h^{dec}_{t-1}) = [x, \\hat{x}_t] \\\\\n",
    "\\textit{write}(h_t^{dec}) = W(h_t^{dec}),\n",
    "\\end{align}\n",
    "\n",
    "although they can be replaced with an attentive neural network to improve the model performance.\n",
    "\n",
    "Below we use the simplest instantiation with GRU cells for encoder and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4shOGt6yg3Tg"
   },
   "outputs": [],
   "source": [
    "T = 16\n",
    "d, nh, D = 32, 100, 28 * 28\n",
    "\n",
    "read = lambda x, y, z: torch.cat([x, y], dim=1)\n",
    "write = nn.Linear(nh, D)\n",
    "\n",
    "enc_rnn = nn.GRUCell(2 * D + nh, 2 * d)\n",
    "dec_rnn = nn.GRUCell(d, nh)\n",
    "\n",
    "# initial hidden states and the initial approximation to a digit\n",
    "h_enc_init = nn.Parameter(torch.zeros(2 * d))\n",
    "h_dec_init = nn.Parameter(torch.zeros(nh))\n",
    "canvas_init = nn.Parameter(torch.zeros(D))\n",
    "\n",
    "write = write.to(device)\n",
    "enc_rnn = enc_rnn.to(device)\n",
    "dec_rnn = dec_rnn.to(device)\n",
    "h_enc_init = h_enc_init.to(device)\n",
    "h_dec_init = h_dec_init.to(device)\n",
    "canvas_init = canvas_init.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZQ-tBF8pb1C"
   },
   "source": [
    "## Task 2: VAE Loss function\n",
    "\n",
    "Implement the loss function for DRAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVagi0SVjRPb"
   },
   "outputs": [],
   "source": [
    "def loss_draw(x, read, enc_rnn, dec_rnn, write, T, h_enc_init, h_dec_init,\n",
    "              canvas_init):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    returns\n",
    "    1. the avergave value of negative ELBO across the minibatch x\n",
    "    2. and the canvases for each step of computations\n",
    "    \"\"\"\n",
    "    # batch_size = x.size(0)\n",
    "    # canvases = [0] * (T + 1)\n",
    "    # canvases[0] = canvas_init.view(1, -1).repeat(batch_size, 1)\n",
    "    # h_enc = h_enc_init.view(1, -1).repeat(batch_size, 1)\n",
    "    # h_dec = h_dec_init.view(1, -1).repeat(batch_size, 1)\n",
    "    pass\n",
    "    # return loss_value, canvases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCrTOR6GsDci"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yk7zy3nuLjI9"
   },
   "outputs": [],
   "source": [
    "train_model(loss_draw, model=[read, enc_rnn, dec_rnn, write, T, h_enc_init,\n",
    "                              h_dec_init, canvas_init], num_epochs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pKfW76oYqtjm"
   },
   "source": [
    "## Visualisation\n",
    "The following two snippets visualize model samples and the generation procedure. \n",
    "- Did DRAW outperform VAE in terms of loss? \n",
    "- Is there any noticeable difference in the quality of samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rJmafaUv0dK"
   },
   "outputs": [],
   "source": [
    "def sample_draw(dec_rnn, write, T, n_samples):\n",
    "    with torch.no_grad():\n",
    "        batch_size = n_samples\n",
    "        canvases = [0] * (T + 1)\n",
    "        canvases[0] = torch.zeros(batch_size, D)\n",
    "        h_dec = torch.zeros(batch_size, nh).to(device) # the initial state\n",
    "    \n",
    "        for t in range(T):\n",
    "            z_t = torch.randn(n_samples, d).to(device)\n",
    "            h_dec = dec_rnn(z_t, h_dec)\n",
    "            canvases[t + 1] = canvases[t] + write(h_dec).cpu()\n",
    "        \n",
    "        canvases = torch.stack(canvases, 0)[1:]\n",
    "        canvases = torch.sigmoid(canvases)\n",
    "        canvases = canvases.view(T, n_samples, 28, 28)\n",
    "        \n",
    "\n",
    "    return canvases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPRXHL6oQF6u"
   },
   "outputs": [],
   "source": [
    "# plots random samples\n",
    "samples = sample_draw(dec_rnn, write, T, n_samples=50)[-1]\n",
    "plot_samples(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXcVN_fgL8mI"
   },
   "outputs": [],
   "source": [
    "# plots the steps of image generation\n",
    "samples = sample_draw(dec_rnn, write, T, n_samples=5)\n",
    "samples = samples.permute(1, 0, 2, 3).contiguous().view(-1, 28, 28)\n",
    "plot_samples(samples, h=5, w=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iljOmVUrUNvj"
   },
   "source": [
    "# Optional Task\n",
    "If you have already completed the above tasks, try proposing a network modification to improve its performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xCaW7ajlmyFR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deep_bayes_VAE_blank.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
